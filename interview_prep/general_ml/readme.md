# Amazon Applied Scientist

1st interview
This round was based on data structures and algorithms. I was asked two medium LC questions. One was to add two numbers given as Linked Lists.

2nd interview
This round was based on breadth and depth of Machine Learning.
We started off by discussing the projects and past internships mentioned in my resume, went on to discuss some (4-5) research papers related to my experience.
Then, the interviewer asked some general ML concepts such as
1) What is regularization? Differentiate between lasso and ridge regularization. Why does regularization lead to sparse weights?
2) What are resnets? How do they work?
3) Difference between MLE and MAP
4) Bias-Variance Tradeoff
5) Precision-Recall in classification
6) K-means clustering
7) Dealing with very large feature spaces
8) SVM
9) Attention in Seq2Seq models
10) Bayesian Learning principle
11) Dimensionality Reduction, PCA
12) What are eigenvectors and eigen values

How is a decision tree created? What is mutual information?
Explain why you need VAE’s over Autoencoders. What is the loss you minimize?
What is batch normalization? How does a batch normalization layer help?
Difference between LSTM’s and GRU’s.
What does peephole keyword in TensorFlow mean for LSTM’s?
What are the different types of text representations used? What is the difference between Word2Vec, Glove, FastText?
What is the difference between Eigen Value Decomposition (EVD) and Singular Value Decomposition (SVD)? When does SVD behave the same as EVD?
What is the difference between bagging and boosting?
What is GBDT? (Gradient Boosted Decision Trees)
Why there is a need for padding in CNN’s?
Explain ResNet architecture.
Difference between Logistic Regression and Linear Regression.
What does maximizing the likelihood function for Logistic Regression mean? What happens if we include some prior over the weights of Logistic Regression? Why we assume prior over the weights?
When does MLE equal to MAP estimate?
Why is it preferred to perform standardization over the features?